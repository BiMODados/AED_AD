{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score,classification_report, f1_score, confusion_matrix,recall_score,precision_score\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_oneway, f_regression, r_regression\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcPlotMatriz(y_test, classificar):\n",
    "    matriz_de_confusao = confusion_matrix(y_test, classificar)\n",
    "    sns.heatmap(matriz_de_confusao, cmap='coolwarm', annot=True, linewidth=1, fmt='d')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def funcMetricas(df_metricas,modelo_Versao, df,Hyper_Parametros,y_test, classificar):\n",
    "    metricas = [\n",
    "        modelo_Versao,\n",
    "        df,\n",
    "        Hyper_Parametros,\n",
    "        accuracy_score(y_test, classificar), \n",
    "        round(recall_score(y_test, classificar, pos_label=0,average='macro'),2),\n",
    "        round(precision_score(y_test, classificar, pos_label=0,average='macro'),2),\n",
    "        round(f1_score(y_test, classificar, pos_label=0,average='macro'),2)\n",
    "        ]\n",
    "    \n",
    "    nova_linha_df = pd.DataFrame([metricas], columns=df_metricas.columns)\n",
    "\n",
    "    df_metricas = pd.concat([df_metricas, nova_linha_df], ignore_index=True)\n",
    "    \n",
    "    return df_metricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo a Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_excel('../Data Cleaning AED/Base_format.xlsx')\n",
    "\n",
    "df = df_original.copy()\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o Dataframe em Valor Explicativo e Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.drop('Status Operacional', axis=1)\n",
    "df_y = df['Status Operacional']\n",
    "\n",
    "df_x = pd.DataFrame(df_x)\n",
    "df_y = pd.DataFrame(df_y)\n",
    "\n",
    "df_y = pd.DataFrame(df_y)\n",
    "display(df_x)\n",
    "display(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando os Dados Qualitativos em Quantitativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encolder = LabelEncoder()\n",
    "\n",
    "preprocessador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categoria', OrdinalEncoder(), make_column_selector(dtype_include=['object','bool']))\n",
    "    ],\n",
    "    remainder='passthrough',  # Mantém as outras colunas inalteradas\n",
    "    verbose_feature_names_out=False,  # Mantém os nomes originais das colunas\n",
    "    \n",
    ")\n",
    "\n",
    "# Ajustar e transformar o DataFrame usando o preprocessador\n",
    "df_x_encoded = preprocessador.fit_transform(df_x)\n",
    "\n",
    "df_y_encoded = label_encolder.fit_transform(df_y)\n",
    "\n",
    "# Se necessário, converter o resultado de volta para um DataFrame, mantendo os nomes das colunas\n",
    "df_x_encoded = pd.DataFrame(df_x_encoded, columns=preprocessador.get_feature_names_out())\n",
    "# Matém a ordem do df original\n",
    "df_x_encoded = df_x_encoded[df_x.columns]\n",
    "\n",
    "df_y_encoded = pd.DataFrame(df_y_encoded, columns=df_y.columns)\n",
    "\n",
    "# df_x_encoded=df_x_encoded[df_x.columns]\n",
    "\n",
    "df_encoded = df_x_encoded.copy()\n",
    "df_encoded['Status Operacional']=df_y_encoded\n",
    "df_encoded\n",
    "\n",
    "display(df_x_encoded)\n",
    "display(df_y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividindo os DataFrames de Teste e Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x_encoded, df_y_encoded, test_size=0.25,random_state=42,shuffle=True)\n",
    "\n",
    "# Salva o array na memoria para guardar a ordem das colunas\n",
    "# X_train = np.ascontiguousarray(X_train)\n",
    "# X_test = np.ascontiguousarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_bayes = GaussianNB()\n",
    "\n",
    "scores = cross_validate(classificador_bayes, X_train, y_train, cv=5, scoring=['accuracy','precision_macro','recall_macro','f1_macro'])\n",
    "chaves = ['test_accuracy','test_precision_macro','test_recall_macro','test_f1_macro']\n",
    "\n",
    "scores_avg = [scores[chave].mean() for chave in chaves] \n",
    "\n",
    "print(scores)\n",
    "print(scores_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_bayes.fit(X_train, y_train)\n",
    "classificar = classificador_bayes.predict(X_test)\n",
    "print(classification_report(y_test,classificar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcPlotMatriz(y_test, classificar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo o Resultado do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação das Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df_encoded[df_encoded.columns.to_list()].corr()\n",
    "\n",
    "sns.heatmap(correlation, annot = True, fmt=\".1f\", linewidths=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a matriz de correlação é possivel dizer que as variaveis são independentes, por conterem pouquíssima correlação muita próxima a 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição das Classes Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos verificar a distribuição das classes, por conta do GaussianNB se comportar mal com classes desbalanceadas. Ele tende a priorizar as classes majoritárias e pode ter dificuldade em prever corretamente as classes minoritárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_y_encoded.value_counts())\n",
    "display(y_train.value_counts())\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes resposta estão bem balanceadas, sem mostrar grandes disparidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste do Modelo Embazado Nos Resultados Anteriores e em Obter o Melhor Desempenho Possível do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando e Tratando Todas as Bases Alterádas em Análise Axploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df = [] # Lista para armazenar os dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df.append(df)\n",
    "\n",
    "df_capping = pd.read_excel('../Data Cleaning AED/Bases/Base_capping.xlsx')\n",
    "display(df_capping.head(2))\n",
    "lista_df.append(df_capping)\n",
    "\n",
    "df_iqr = pd.read_excel('../Data Cleaning AED/Bases/Base_iqr.xlsx')\n",
    "display(df_iqr.head(2))\n",
    "lista_df.append(df_iqr)\n",
    "\n",
    "df_log = pd.read_excel('../Data Cleaning AED/Bases/Base_log.xlsx')\n",
    "display(df_log.head(2))\n",
    "lista_df.append(df_log)\n",
    "\n",
    "df_raiz = pd.read_excel('../Data Cleaning AED/Bases/Base_sqrt.xlsx')\n",
    "display(df_raiz.head(2))\n",
    "lista_df.append(df_raiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_capping.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in enumerate(lista_df):\n",
    "    ordem_colunas = lista_df[k].columns\n",
    "    lista_df[k] = preprocessador.fit_transform(v)\n",
    "    lista_df[k] = pd.DataFrame(lista_df[k], columns=preprocessador.get_feature_names_out())\n",
    "    lista_df[k] = lista_df[k][ordem_colunas]\n",
    "\n",
    "# Lista com todos os dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_bayes.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta pipeline será utilizada para, organizar os passos de transformação de dados e para tentar aplicar o melhor modelo possivel nas condições do nosso caso. Além disso, ela também é muito util para replicar o processo em outros modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicação da Pipe\n",
    "\n",
    "df_metricas: DataFrame para armazenar o nome do modelo, a base de dados utilizada, as métricas de teste, e a melhor combinação de hiperparâmetros encontrada para cada base de dados.\n",
    "\n",
    "pipe: Variável que armazena o pipeline completo, contendo todas as etapas de pré-processamento e modelo.\n",
    "\n",
    "StandardScaler: Centraliza e normaliza os dados, subtraindo a média e dividindo pelo desvio padrão, o que torna a dispersão dos dados mais uniforme.\n",
    "SelectKBest: Seleciona as variáveis mais importantes, reduzindo a dimensionalidade para facilitar a interpretação e reduzir o número de perguntas aos usuários.\n",
    "PCA (Principal Component Analysis): Reduz a dimensionalidade após o SelectKBest, preservando a variância máxima.\n",
    "DecisionTreeClassifier: Modelo de árvore de decisão utilizado após a redução de dimensionalidade.\n",
    "params_pipe: Dicionário com os parâmetros da pipeline para otimização.\n",
    "\n",
    "SelectKBest__k e pca__n_components: Definem a quantidade de variáveis a serem mantidas na redução dimensional.\n",
    "SelectKBest__score_func: Função de avaliação para selecionar as variáveis mais relevantes.\n",
    "model__criterion, model__max_depth, model__min_samples_split, e model__min_samples_leaf: Hiperparâmetros específicos da árvore de decisão para otimizar a capacidade de generalização.\n",
    "valores_k: Lista que define o número máximo de variáveis a serem selecionadas (até 10) pelo SelectKBest.\n",
    "\n",
    "GridSearchCV: Realiza uma busca em grade sobre diferentes combinações de hiperparâmetros na pipeline, aplica validação cruzada e seleciona a melhor combinação com base na acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DataFrame para armazenar as métricas\n",
    "df_metricas = pd.DataFrame(columns=['Modelo','DF','Hyper_Parametros','Acuracia','Recall_Media', 'Precision_Media', 'F1_Score_Media'])\n",
    "\n",
    "# Variáveis para armazenar o melhor modelo e sua acurácia\n",
    "melhor_acuracia = 0\n",
    "melhor_classificador = None\n",
    "melhor_base = None\n",
    "\n",
    "# Iterando sobre cada DataFrame da lista\n",
    "for i, data_frame in enumerate(lista_df):\n",
    "    # Dividindo dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_frame[data_frame.columns[:-1]], data_frame['Status Operacional'], test_size=0.25, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('SelectKBest', SelectKBest()),\n",
    "        ('pca', PCA()),\n",
    "        ('model', GaussianNB())  # GaussianNB Classifier\n",
    "    ])\n",
    "    \n",
    "    # Hiperparâmetros\n",
    "    params_pipe = []\n",
    "    valores_k = range(1, 11)\n",
    "\n",
    "    for k in valores_k:\n",
    "        for n in range(1, k + 1):\n",
    "            params_pipe.append({\n",
    "                # 'SelectKBest__k': [k],  # Comentei essa linha pois estava comentada no código original\n",
    "                'pca__n_components': [n],\n",
    "                'SelectKBest__score_func': [f_classif, f_oneway, f_regression, r_regression],\n",
    "                'model__var_smoothing': np.logspace(0, -9, num=100)  # Parâmetro ajustado para GaussianNB\n",
    "            })\n",
    "\n",
    "    # Busca em grade\n",
    "    grid_search = GridSearchCV(estimator=pipe, param_grid=params_pipe, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "    # Treinando o modelo\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Melhor modelo encontrado para essa base\n",
    "    classificador_grafico = grid_search.best_estimator_\n",
    "\n",
    "    # Avaliação do modelo\n",
    "    previsao = classificador_grafico.predict(X_test)\n",
    "    acuracia = grid_search.best_score_\n",
    "\n",
    "    # Comparar com a melhor acurácia até agora\n",
    "    if acuracia > melhor_acuracia:\n",
    "        melhor_acuracia = acuracia\n",
    "        melhor_classificador = classificador_grafico\n",
    "        melhor_base = i  # Guardar o índice da melhor base\n",
    "\n",
    "    # PCA para análise\n",
    "    pca = classificador_grafico.named_steps['pca']\n",
    "    kBest = classificador_grafico.named_steps['SelectKBest']\n",
    "    \n",
    "    components_df = pd.DataFrame(pca.components_, columns=data_frame.columns[kBest.get_support(indices=True).tolist()])\n",
    "\n",
    "    # Plotagem da Matriz de Loadings\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(components_df, cmap='viridis', annot=True)\n",
    "    plt.xlabel('Características Originais')\n",
    "    plt.ylabel('Componentes Principais')\n",
    "    plt.title(f'Matriz de Loadings - Base {i+1}')\n",
    "    plt.show()\n",
    "\n",
    "    # Analisando os resultados\n",
    "    melhor_params = grid_search.best_params_\n",
    "    metricas = classification_report(y_test, previsao)\n",
    "    print(f\"Melhores parâmetros (Base {i+1}):\", melhor_params)\n",
    "    print(f\"Melhor acurácia (Base {i+1}):\", acuracia)\n",
    "    print(metricas)\n",
    "\n",
    "    funcPlotMatriz(y_test, previsao)  # Presumindo que essa função já esteja implementada\n",
    "\n",
    "    # Atualizando DataFrame de métricas\n",
    "    df_metricas = funcMetricas(df_metricas, 'GaussianNB', data_frame, melhor_params, y_test, previsao)\n",
    "\n",
    "# Exibir as métricas finais\n",
    "display(df_metricas)\n",
    "\n",
    "# Exibir qual foi a melhor base\n",
    "print(f\"A melhor base foi a Base {melhor_base+1} com acurácia de {melhor_acuracia}\")\n",
    "\n",
    "# Serializando o melhor modelo (Pipeline completo) da melhor base\n",
    "with open('melhor_modelo_gaussiannb_base_log.pkl', 'wb') as arquivo:\n",
    "    pickle.dump(melhor_classificador, arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algumas Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À primeira vista, a mudança pode parecer pequena, porém, tive que forçar o modelo a trabalhar com no máximo 10 colunas de características, uma redução significativa para um modelo que possuía 16 colunas no treinamento. Mesmo assim, ele conseguiu manter resultados semelhantes no teste simples e, em alguns casos, até melhores.\n",
    "\n",
    "Outras conclusões que podem ser tiradas são que as colunas selecionadas, que tiveram o melhor desempenho na validação cruzada (Cross-Validation), foram:\n",
    "\n",
    "- Age\n",
    "- Height\n",
    "- Weight\n",
    "- family_history_with_overweight\n",
    "- FAVC\n",
    "- CAEC\n",
    "- CH20\n",
    "Por fim, as métricas obtidas pelo modelo não foram das melhores, e é provável que este não seja o melhor modelo para essa base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas.to_excel('./Metricas/metricas_bayes.xlsx', sheet_name='bayes_knn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(melhor_classificador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
